---
title: 'Count Data Regression: Modeling Daily Count of New Covid Cases'
author: "Jonathan Amdur"
date: "12/14/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, include=FALSE}
# Packages
#install.packages('spaMM', dependencies = TRUE)
#install.packages('Rcpp', dependencies = TRUE)

# Libraries
library(MASS)
library(spaMM)
library(olsrr)
library(boot)

# Read in data and remove index
df_covid_cases = read.csv("~/Documents/school/Stochastics/project/covid_cases_prepped.csv")
df_covid_cases = df_covid_cases[-c(1)]

# Check data
head(df_covid_cases)
df_cor = cor(df_covid_cases)
print(df_cor)

# Removing country names -> REMOVE AND MOVE TO PYTHON CODE?
# Country that would make this region specific rather than a general model to fit the pandemic
df_covid_cases_general = df_covid_cases[,-which(names(df_covid_cases) %in% c("CAN",'USA','GBR','IND','KOR','SWE'))]

# Checking dispersion
new_sample_var <- var(df_covid_cases_general$new_cases)
new_sample_mean <- mean(df_covid_cases_general$new_cases)
disp <- new_sample_var/new_sample_mean
paste(c('Sample Dispersion:', disp,'Sample Variance:',new_sample_var,'Sample Mean:',new_sample_mean))
```
```{r, include=FALSE, warning=FALSE}
library(reticulate)
py_install("seaborn")
```

Beginning in January of 2020, the novel corona virus COVID-19 had started to appear in the news and around the world. The who began tracking it to ensure the growth of it did not get out of hand. As the virus spread and more was learned about how it works, grows, and spreads, more and more data collection allowed us to track the daily count of new covid cases. As time has gone on, we have seen new ways of combating the virus take affect from lockdowns to vaccinations and boosters. With this data, we can model the progression of these daily covid cases which can help explain what techniques are working, what is failing, and when the next wave of the virus is coming. With this in hand, front line workers and decision makers can utilize mathematical regression models on count data to ensure the safety and continued success fighting the virus. Now, our goal is to find the best fitting model from the linear regression model, Poisson GLM, Negative Binomial GLM, and COM-Poisson GLM for the count of daily new covid cases in 6 countries studied.
\
\
Data for this project was sourced from https://ourworldindata.org/coronavirus. This data is a daily aggregation of key country statistics and tracked factors that are known to affect Covid-19 case rates. This dataset contained 134,015 rows and 67 columns for data from 1/1/2020 through 11/17/2021. This represented tracked features for 237 countries across the globe. The amount of data for each vountry varied based on variability, so the decision was made to limit to just 6 countries. This was done based on the study design in the _Count regression models for COVID-19_ study, which varied the countries based on length of covid presence and geographic locations. The countries of Canada, United States, Great Britain,India,Korea,and Sweden were chosen as our representative countries based on similar criteria to the study, as well as the variety of lockdown approaches and availability of data for the first confirmed cases. For all countries, the new_cases variable represents the daily count of Covid-19 and is our target variable for the proposed count models. Analysis on this variable revealed that while counts should be strictly positive, a few countries did include negative entries. These entries were investigated and while the initial assumption was that they were indicating corrections to previously reported cases, this was not the case and seemed to be an error. To handle these values and ensure a proper count model was performed, the absolute value of these were taken and the negatives assumed to be erroneous.
\
\
While performing initial analysis, 3 new variables were also created to ensure dates were usable for the model building process. The days_covid_present variable represents the days between the date field and the first date where the new_count was greater than 0, which represnts the first confirmed case(s). This variable allows us to model new cases based on how far into the pandemic each country is, rather than the specific date which has varied points in the lifecycle. Further, the date columns month and year were preserved as numeric columns to account for seasonality of the virus. It has been seen that the case count does increase in the winter months so these new variables allowd for that to be accounted for. Since all countries are located in the northern hemisphere, the season also will align and means these variables make sense within the context of the model.
\
\
With these new variables created, basic data cleaning and null value imputation was performed. It was found that many columns were unecessary since they were just duplicates, smoothed, or scaled versions of the same data, or completely null. These variables were dropped from the data. Further analysis showed that for all total columns, the current days counts were already pre-added. To ensure the total was representative of the total up to that point, which would remove the new days count from affecting the new covid case count variable, the corresponding new count variables amount was subtracted for the total of that day. Once the variables were cleaned up, null value imputation was performed to ensure there was no missing values in the data. For variables with nulls specific to countries, recent news articles were consulted to fill out total boosters and the mean of all other counties was used to fill out missing days. For all other nulls, 3 approaches were taken. First, for any value that represented a running total, any day before the first day with a non-null value was assumed to mean no affect was present, such as no people fully vaccinated before the first time a fully vaccinated person was counted, and a 0 was used in place of null. Second, for any nulls in a running total that had values the day(s) before or after, such as total_tests, the last valid value from the country was used for the running total.  Finally, standard mean imputation was used for anything still remaining. 
\
\

```{r, echo=FALSE,fig.cap='Covid Cases By Days Present'}
plot(df_covid_cases_general$days_covid_present,df_covid_cases_general$new_cases)
```
 
 
```{python, echo=FALSE, fig.cap="Correlation of All Variables"}
import seaborn as sb
import pandas as pd
df_covid_cases_general = pd.DataFrame(r.df_covid_cases_general)

corr1=df_covid_cases_general.corr()
sb.heatmap(corr1, 
           xticklabels=corr1.columns,
           yticklabels=corr1.columns) 
```
Initial analysis was performed on the data. From figure 1 we see that there is a nonliner relationship between days_covid_present and new_cases variable. We also notice that there are several patterns within the data. This indicates that this may be a mixture model or that separate models for each country will be a better representation than one total model. We will consider the multiple model approach. Further, we also investigated the data dispersion to see how well the models might fit. We found that for the new_cases variable the sample mean is 23945.7748361069, the sample variance is 2546551497.35433, and the sample standard deviation is 50463.37. We notice a large standard deviation and a variance greater than the mean. These point to overdispersion of the data, which makes sense as the growth is exponential and cyclical. Now, for the variables at hand we look to figure 2 to see how the pearson correlation between all variables looks. By the heatmap in figure 2, we see there are multiple variables that show a very strong correlation to each other. This indicates that there is collinearity between multiple factors in the variables and so we may need to further remove variables for modeling purposes. This makes sense since some variables are static by country, such as population over 65 or gdp. When one is present, it automatically means there are relationships between it and anything else that is static at that country. Thus, we will be careful to remove any colinear variables within the models. 
\
\
Now, to model the count of Covid-19 cases, we look to the literature contained in the _Introduction to Linear Regression Analysis_, _Count Regression Models for COVID-19_, _USE OF POISSON REGRESSION MODELS IN ESTIMATING INCIDENCE RATES AND RATIOS_ and _A Flexible Regression Model for Count Data_. We want to attempt 4 different models so we can pick the best one for this data. 
\
\
The first choice is the multvariate linear regression model. This standard model assumes the errors are i.i.d Normal with $\epsilon_{i} \in N(0, \sigma^{2})$ and the $\epsilon$ uncorrelated. It also assumes that linear relationship exists between the features and target variable modeled by 
$$
y_{i} = \beta_{0}+\beta_{1}x_{1}+\cdots+\beta_{n}x_{n}+\epsilon_{i}
$$
Given these assumptions, we do not expect this model to work best. From _An Intermediate Course in Probability_, _Introduction to Linear Regression Analysis_, and _A Flexible Regression Model for Count Data_, we note that count data is best modeled typically by a Poisson distribution. Further, these assumptions most likely do not hold based on our analysis. The data showed increasing trends over time that were non linear in nature and it's likely the errors are non-normal or uncorrelated. Now, we compute this regression model in order to confirm these hypothese. To comput this, we utilize R's lm() function. We first build the full model utilizing the cleaned up data from the python program, with the individual countries removed to make this model more general. We will consider rebuilding this with these back in if the model calls for it.The model output for this follows the model
$$
\hat{y_{i}}=\hat{\beta_{0}}+\hat{\beta_{1}}x_{1}+\cdots+\hat{\beta_{n}}x_{n}
$$
The output corresponding to this is below. 
```{r, echo=FALSE}
linear_model <- lm(new_cases ~ ., data = df_covid_cases_general)
linear_model$coefficients
```
We notice that the $R^2$ value is not terrible at .8, indicating 80% of the total variance in the count of covid cases is explained by this model. Looking at the variables, we first note that there are multiple NA coefficient estimates. These are due to the collinearity and thus are not included in the model. Further, there are multiple cases where there is no significance to the variable based on the t-test handled by R. Thus, there are multiple variables that may be unnecessary given the rest of the variables contained within the model. Now, to combat this we utilize the olsrr package ols_step_both_p that performs stepwise regression. In this, all variables previously entered into the model are evaluated for significance using the t-test and if the p-value is greater than the removal requirement, it is removed from the model, and if a new variables p-value is less than the entrance requirement, it is added. This continues until no new variables are removed or added and a final model with all relevant variables are chosen. Below is the output of this model. We see the nonsignificant and colinear variables have now been removed. We will use this as our final linear model for evaluation.
```{r,echo=FALSE}
# Stepwise regression
linear_model_step <- ols_step_both_p(linear_model, pent=.1, prem=.1)
linear_model_step$model$coefficients
```
\
\
The second choice is the poisson regression model. This standard model assumes the errors are not i.i.d Normal, but that the model can be made linear utilizing a link function. It also assumes that mean and variance are equivalent. From the analysis, we note that the assumption of equivalent variance and expectation is violated. From _A Flexible Regression Model for Count Data_ and _Count Regression Models for COVID-19_, we note that overdispersed data will be best served by COM-Poisson or Negative Binomial. To compute this model, we utilize R's glm() function with a log-linked poisson family. We first build the full model. The coefficient output for this is 
$$
\hat{\mu_{i}}=\hat{y_{i}}=e^{\hat{\beta_{0}}+\hat{\beta_{1}}x_{1}+\cdots+\hat{\beta_{n}}x_{n}}
$$
The output corresponding to this is below. 
```{r, echo=FALSE}
poi_glm <- glm(abs(new_cases) ~ ., 
               data = df_covid_cases_general, 
               family = "poisson")
poi_glm$coefficients
```
We notice that the null deviance is significantly larger than the residual deviance, suggesting good model fit.  We again perform stepwise regression, but this time using the Akaike Information Criterion(AIC) and the stepAIC() function from R. This works as before but replaces the t-test with the lowering of the AIC, which represents the estimated prediction error. The output model is below. 
```{r,include=FALSE}
# Stepwise regression
poi_glm_step <- stepAIC(poi_glm)
```
```{r, echo=FALSE}
poi_glm_step$coefficients
```
\
\
Our third choice is the negative binomial regression model. This model is similar to the poissoin, but it does not assume that mean and variance are equivalent and allows for under/overdispersion. From the analysis, we note that the assumption of equivalent variance and expectation is violated so this should fit well. By https://data.library.virginia.edu/getting-started-with-negative-binomial-regression-modeling/ we note that we can relate estimate the theta parameter usingthe sample variance and means. By the site we have that $\sigma^{2} = \mu+\mu^{2}/\theta$ so we use the sample estimates to create an estimate of theta as $\hat{\theta} = \bar{X}^{2}/(S_{x}^{2}-\bar{X})$To compute this model, we utilize R's glm() function with a log-linked negative binomial family and the estimated theta of 0.2252. We first build the full model. The coefficient output for this is 
$$
\hat{\mu_{i}}=\exp(\ln(\theta_{i})+\beta_{1}x_{1}+\beta_{2}x_{2}+\cdots+\beta_{k}x_{k})
$$
The output corresponding to this is below. 
```{r, include=FALSE}
# Estimate theta (dispersion) parameter for Negative Binomial
theta_est <- (new_sample_mean^2)/(new_sample_var-new_sample_mean)
theta_est
```
```{r,echo=FALSE}

nb_glm <- glm(abs(new_cases) ~ ., 
              data = df_covid_cases_general, 
              family = negative.binomial(theta = theta_est, link = "log"))
nb_glm$coefficients
```
We notice that the null deviance is significantly larger than the residual deviance, suggesting good model fit. Similar issues arrise in the model as did in the linear model.  We again perform stepwise regression using the Akaike Information Criterion(AIC) and the stepAIC() function from R. T The output model is below. 
```{r,include=FALSE}
# Stepwise regression
nb_glm_step <- stepAIC(nb_glm)
```
```{r,echo=FALSE}
nb_glm_step$coefficients
```
\
\
Our final choice is the Conway-Maxwell Poisson (COM-Poisson) regression model coming from the _A Flexible Regression Model for Count Data_ paper. This model is similar to the poisson, but it does not assume that mean and variance are equivalent, allowing for under/overdispersion, and it accounts for this utilizing a dispersion parameter $\nu$ and a normalization factor. From the analysis, we know that the assumption of equivalent variance and expectation is violated so this should fit well. 
To compute this model, we utilize R's glm() function with a COM-Poisson family, from the spaMM package, and the estimated $\nu$ of 0.7. We first build the full model. The coefficient output for this is 
$$
\hat{y_{i}}|x_{i} = \hat{\lambda}^{a/\hat{\nu}}-\frac{\hat{\nu}-1}{2\hat{\nu}}, \\
\hat{\lambda} = \exp(x_{i}'\beta)
$$
The output corresponding to this is below. 
```{r, include=FALSE}
# Estimating nu by relation on pg. 946
nu_est <- new_sample_mean/new_sample_var
```
```{r}
# Run model
com_poi_glm <- glm(abs(new_cases) ~ ., data = df_covid_cases_general, family = COMPoisson(nu=.7))
com_poi_glm$coefficients
```
We notice that the null deviance is significantly larger than the residual deviance, suggesting good model fit. Similar issues arrise in the model as did in the linear model.  We again perform stepwise regression using the Akaike Information Criterion(AIC) and the stepAIC() function from R. Due to compute power the stepwise did not work so the variables from previous models were used to compute this. The output model is below. 
```{r,include=FALSE}
# Stepwise regression
step_df = df_covid_cases_general[,which(names(df_covid_cases_general) %in% c(names(poi_glm_step$coefficients),'new_cases'))]
com_poi_glm_step <-glm(abs(new_cases) ~ ., data = step_df, family = COMPoisson(nu=.7))
```
```{r,echo=FALSE}
nb_glm_step$coefficients
```

\
\
Now, we must asses these models for adequacy. Note, all plots were placed in the appendix to conserve discussion space. We performed regression analysis on each of the models. For the linear model, this involved utilizing the residuals to compute a normal q-q plot and to plot the residuals vs. predicted response. For the generalized linear models, the residuals is replaced with the deviance residuals as per the _Introduction to Linear Regression Analysis_. Further, for the COM-Poisson model, Sellers and Shmueli reccommend using bootstrapped deviance residuals for the q-q plot pulling from the empiric distribution. This was completed utilizing the boot package in r and running the diagnostic plots. We see that for the linear model, generally it fits well for larger predicted responses, but struggles with the smaller responses. Further, the normal assumption is slightly violated with a heavy left and right tail. A transformation could improve the fit of this model. Overall, this doesn't fit the data great but it does fit well enough. Lookign at our glm models, we see that the Poisson and COM-Poisson have the best fits according to our adequacy checks according to the q-q plot. The negative binomial has the best residual vs. predicted response plot indicating it has consistent variance unlike the other 2 models. Further, from the COM-Poisson and Poisson diagnosis plots we see that the variance is not consistent and varies by the outward facing cone shape in the predicted vs. residual plot. This makes sense as the pandemic has changed as new variants have come about through mutations and lockdowns have come and gone in some places, but returned in others. Thus, a better fit for COM-Poisson may be achieved threw a model that can handle non-consistent error and variance. Overall, our chosen models do adequately fit our data. 
\
\
Finally, to compare our models we utilize the mean squared error (MSE), the AIC of the model, and the predicted outputs vs. days covid present plots in the appendix. the output below shows our evaluation criteria.
```{r, include=FALSE}
# Model comparisons
# AIC
lm_aic <- AIC(linear_model_step$model)
poi_aic <- AIC(poi_glm_step)
nb_aic <- AIC(nb_glm_step)
cpoi_aic <- AIC(com_poi_glm_step)
# MSE
model_summ <- summary(linear_model_step$model)
lm_mse <- mean(model_summ$residuals^2)
poi_mse <- mean(poi_glm_step$residuals^2)
nb_mse <- mean(nb_glm_step$residuals^2)
cpoi_mse <- mean(com_poi_glm_step$residuals^2)
```
```{r, echo=FALSE}
paste0('Linear Model Evaluation: ')
paste0(c('AIC = ', lm_aic, 'MSE =', lm_mse))
paste0('Poisson Model Evaluation: ')
paste0(c('AIC = ', poi_aic, 'MSE = ', poi_mse))
paste0(c('Negative Binomial Model Evaluation: '))
paste0(c('AIC = ', nb_aic, 'MSE = ', nb_mse))
paste0(c('COM-Poisson Model Evaluation: '))
paste0(c('AIC = ', cpoi_aic, 'MSE = ', cpoi_mse))
```
We see that the AIC of the Negative Binomial GLM is the lowest, followed by the Linear Model, COM-Poisson, and then Poisson GLM. This indicates that the Negative Binomial model will have the lowest prediction error compared to the rest of the models. However, the interpretability of the linear model does make a case for its use as well. Further, the Negative Binomial model has significantly lower mean squared error when compared to the rest of the models. Turning to the plots in the appendix of the predicted vs. days since covid present, we see that partly why the negative binomial fits so well is because it is mainly fit for the countries that have little volume. It misses the major spikes in the model. However, it seems this works well for the majority of the countries. Looking at the other plots, we see that the COM-Poisson model did not fit this data very well. The plot shows points scattered about and not much fitting to the data. Now, we see for Poisson and Linear that these do fit the data well but the spikes are located at different points than expected. This is likely due to other features interaction and so we can account it for that. These also account for the large spikes, unlike the negative binomial, making them decent candidate models. Taking these all into account, based on the study done the model choice that best generalizes from our data is the Negative Binomial GLM. 
\
\
Through this study, we have found that for the count of daily new covid cases in the 6 countries studied that the Negative Binomial GLM is the model that best fits our count data. It produces the least error estimate and has a good fit to the less extreme counts. For more extreme counts of cases, the Poisson and Linear models seemed to have the best fits and were able to account for the large spikes unlike the Negative Binomial. Further, the interpretability of the linear model makes for a decent second choice. Finding relationships in the coefficients allows for easier study of the change in counts that certain new developments have had over time. Looking at the coefficients of the linear model, we can say that vaccination and boosters have a negative relationship with the count of cases, indicating that for each new patient vaccinated we expect a decrease in the number of total new cases each day. Utilizing these modeling techniques, we can learn more about a new and rapidly chaninging pandemic. Future work on these models, and potentially including more epidemiological models or branching processes, and greater fit can unlock more knowledge about a novel virus, aiding those fighting it on the front line.

\pagebreak
# Appendix - Model Evaluation
##Linear Model Evaluation
```{r,echo=FALSE, fig.cap='Linear Model Evaluation'}
# LM RESIDUAL ANALYSIS
# QQ plot
st_res_lm_step=rstudent(linear_model_step$model)
qqnorm(st_res_lm_step,
       ylab="Expected Normal Residual",
       xlab="Studentized Residuals",
       main="Linear Model Normal Probability Plot")
qqline(st_res_lm_step)

# Res vs Predicted
plot(predict(linear_model_step$model),st_res_lm_step, 
     main="Linear Model Residual vs Predicted Response",
     xlab="Predicted Response",
     ylab="Residual")
abline(h=0)

# Visualize linear model
plot(df_covid_cases_general$days_covid_present[order(df_covid_cases_general$days_covid_present)],
     predict(linear_model_step$model), 
     main="Linear Model Predicted and True Covid Counts",
     xlab="Days Covid Present",
     ylab="Count of New Cases")
points(df_covid_cases_general$days_covid_present[order(df_covid_cases_general$days_covid_present)], 
       df_covid_cases_general$new_cases[order(df_covid_cases_general$days_covid_present)], 
       col = 'red', 
       pch=16)
```

##Poisson Model Evaluation
```{r,echo=FALSE, fig.cap='Poisson Model Evaluation'} 
# Compute deviance residuals 
poi_dev_resid=resid(poi_glm_step)
glm.diag.plots(poi_glm_step)

# Visualize Poisson Model
plot(df_covid_cases_general$days_covid_present[order(df_covid_cases_general$days_covid_present)],exp(predict(poi_glm_step)), 
     main="Poisson GLM Predicted and True Covid Counts",
     xlab="Days Covid Present",
     ylab="Count of Covid Cases",
     col='red')
points(df_covid_cases_general$days_covid_present[order(df_covid_cases_general$days_covid_present)], 
       df_covid_cases_general$new_cases[order(df_covid_cases_general$days_covid_present)], 
       col = 'black')
```
  
##Negative Binomial Model Evaluation     
```{r,echo=FALSE, fig.cap='Negative Binomial Model Evaluation'}
# Compute deviance residuals 
nb_dev_resid=resid(nb_glm_step)
glm.diag.plots(nb_glm_step)

# Visualize NB Model
plot(df_covid_cases_general$days_covid_present[order(df_covid_cases_general$days_covid_present)],exp(predict(nb_glm_step)), 
     main="Negative Binomial GLM Predicted and True Covid Counts",
     xlab="Days Covid Present",
     ylab="Count of Covid Cases",
     col='red')
points(df_covid_cases_general$days_covid_present[order(df_covid_cases_general$days_covid_present)], 
       df_covid_cases_general$new_cases[order(df_covid_cases_general$days_covid_present)], 
       col = 'black')
```
  
    
```{r,echo=FALSE, fig.cap='COM-Poisson Model Evaluation'}
# Compute deviance residuals 
glm.diag.plots(com_poi_glm_step)

# Visualize COMPoisson Model
plot(df_covid_cases_general$days_covid_present[order(df_covid_cases_general$days_covid_present)],exp(predict(com_poi_glm_step)), 
     main="COM Poisson GLM Predicted and True Covid Counts",
     xlab="Days Covid Present",
     ylab="Count of Covid Cases",
     col='red')
points(df_covid_cases_general$days_covid_present[order(df_covid_cases_general$days_covid_present)], 
       df_covid_cases_general$new_cases[order(df_covid_cases_general$days_covid_present)], 
       col = 'black')
```

  
\pagebreak

# Bibliography

1.	Hannah Ritchie, Edouard Mathieu, Lucas Rodés-Guirao, Cameron Appel, Charlie Giattino, Esteban Ortiz-Ospina, Joe Hasell, Bobbie Macdonald, Diana Beltekian and Max Roser (2020)\\ - "Coronavirus Pandemic (COVID-19)". Published online at OurWorldInData.org. Retrieved from: 'https://ourworldindata.org/coronavirus' [Online Resource]\\

2.	David Inouye, Eunho Yang, Genevera Allen, and Pradeep Ravikumar (2017) – A review of multivariate distributions for count data derived from the Poisson distribution\\

3.	https://www.rdocumentation.org/packages/boot/versions/1.3-28/topics/glm.diag.plots\\

4.	Douglas Montgomery, Elizabeth Peck, G. Geoffrey Vining (2012) - Introduction to Linear Regression analysis, 5th edition\\

5.	Chan, Stephen et al. “Count regression models for COVID-19.” Physica A vol. 563 (2021): 125460. doi:10.1016/j.physa.2020.125460\\

6.	https://data.library.virginia.edu/getting-started-with-negative-binomial-regression-modeling/.\\

7.	EDWARD L. FROME, HARVEY CHECKOWAY, USE OF POISSON REGRESSION MODELS IN ESTIMATING INCIDENCE RATES AND RATIOS, American Journal of Epidemiology, Volume 121,Issue2,February1985,Pages309-323, https://doi.org/10.1093/oxfordjournals.aje.a114001\\

8.	Allan Gut (2009) - An Intermediate Course in Probability\\

9.	Karlis, Dimitris. “Multivariate Poisson Models.” Athens University of Economics, 2002, http://www2.stat-athens.aueb.gr/~karlis/multivariate%20Poisson%20models.pdf.\\

10.	Inouye, David et al. “A Review of Multivariate Distributions for Count Data Derived from the Poisson Distribution.” Wiley interdisciplinary reviews. Computational statistics vol. 9,3 (2017): e1398. doi:10.1002/wics.1398\\
